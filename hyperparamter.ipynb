{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urdu Clinical Emotion Recognition - Hyperparameter Tuning\n",
    "\n",
    "This notebook runs the hyperparameter search to find optimal model configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.dirname('.'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from hyperparameter_tuning import grid_search\n",
    "\n",
    "# Run the grid search\n",
    "grid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_grid_search():\n",
    "    # Find the latest grid search directory\n",
    "    exp_dir = 'experiments'\n",
    "    searches = [d for d in os.listdir(exp_dir) if d.startswith('grid_search_')]\n",
    "    latest_search = sorted(searches)[-1]\n",
    "    search_dir = os.path.join(exp_dir, latest_search)\n",
    "    \n",
    "    # Load results\n",
    "    with open(os.path.join(search_dir, 'results.json'), 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Plot accuracy vs parameters\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(results_df['params'], results_df['val_acc'])\n",
    "    plt.xlabel('Number of Parameters')\n",
    "    plt.ylabel('Validation Accuracy (%)')\n",
    "    plt.title('Model Size vs Performance')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display top 5 models\n",
    "    top_models = results_df.sort_values('val_acc', ascending=False).head()\n",
    "    display(HTML(\"<h3>Top 5 Models</h3>\"))\n",
    "    display(HTML(top_models.to_html()))\n",
    "    \n",
    "    # Load and display analysis\n",
    "    with open(os.path.join(search_dir, 'analysis.json'), 'r') as f:\n",
    "        analysis = json.load(f)\n",
    "    \n",
    "    display(HTML(\"<h3>Best Model Configuration</h3>\"))\n",
    "    best_config = pd.DataFrame([analysis['best_accuracy']['config']])\n",
    "    display(HTML(best_config.to_html()))\n",
    "\n",
    "# Analyze the grid search results\n",
    "analyze_grid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Experiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_experiment(exp_dir):\n",
    "    # Load metrics\n",
    "    metrics_df = pd.read_csv(os.path.join(exp_dir, 'data/training_metrics.csv'))\n",
    "    report_df = pd.read_csv(os.path.join(exp_dir, 'data/classification_report.csv'))\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(metrics_df['epoch'], metrics_df['train_loss'], label='Train')\n",
    "    plt.plot(metrics_df['epoch'], metrics_df['val_loss'], label='Validation')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(metrics_df['epoch'], metrics_df['train_acc'], label='Train')\n",
    "    plt.plot(metrics_df['epoch'], metrics_df['val_acc'], label='Validation')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display classification report\n",
    "    display(HTML(report_df.to_html()))\n",
    "\n",
    "# Example: Analyze a specific experiment\n",
    "# analyze_experiment('experiments/grid_search_YYYYMMDD_HHMMSS/exp_YYYYMMDD_HHMMSS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}